{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import lightning as L\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rootutils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "root_p = rootutils.setup_root(search_from=os.getcwd(), indicator=\".project-root\")\n",
    "\n",
    "from src.data.mnist_datamodule import MNISTDataModule\n",
    "from src.models.vae_components.vanilla_vae import VAE\n",
    "from src.models.vae_module import VAEModule\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dm = MNISTDataModule(num_workers=0, transform=\"default\")\n",
    "model = VAE(input_dim=784, hidden_dim=400, latent_dim=200)\n",
    "\n",
    "# pl_module = VAEModule(model, lr=0.001)\n",
    "# Implement training routine myself\n",
    "dm.setup(\"fit\")\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataloader\n",
    "dataiter = iter(dm.train_dataloader())\n",
    "batch = next(dataiter)\n",
    "\n",
    "num_samples = 25\n",
    "sample_images = [batch[0][i, 0] for i in range(num_samples)]\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(5, 5), axes_pad=0.1)\n",
    "\n",
    "for ax, im in zip(grid, sample_images):\n",
    "    ax.imshow(im, cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training routine\n",
    "\n",
    "\n",
    "def loss_function(x, x_hat, mean, log_var):\n",
    "    # Loss function from https://github.com/AntixK/PyTorch-VAE/blob/master/models/vanilla_vae.py\n",
    "    recons_loss = nn.functional.mse_loss(x_hat, x)\n",
    "    kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mean**2 - log_var.exp(), dim=1), dim=0)\n",
    "\n",
    "    return recons_loss + kld_loss\n",
    "\n",
    "\n",
    "def train(model, optimizer, epochs, device):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        overall_loss = 0\n",
    "        for batch_idx, (x, _) in enumerate(dm.train_dataloader()):\n",
    "            N, C, H, W = x.size()\n",
    "            x = x.reshape(N, -1)\n",
    "            x = x.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x_hat, mean, log_var = model(x)\n",
    "            loss = loss_function(x, x_hat, mean, log_var)\n",
    "\n",
    "            overall_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(\"\\tEpoch\", epoch + 1, \"\\tAverage Loss: \", overall_loss / (batch_idx * N))\n",
    "    return overall_loss\n",
    "\n",
    "\n",
    "train(model, optimizer, epochs=10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from Lightning checkpoint\n",
    "pl_module = VAEModule.load_from_checkpoint(\n",
    "    root_p / \"logs\" / \"vanilla_vae\" / \"runs\" / \"2023-12-20_11-01-43\" / \"checkpoints\" / \"last.ckpt\",\n",
    "    model=model,\n",
    ")\n",
    "model = pl_module.model\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def generate_digit(mean, var):\n",
    "    z_sample = torch.tensor([[mean, var]], dtype=torch.float).to(device)\n",
    "    x_decoded = model.decode(z_sample)\n",
    "    digit = x_decoded.detach().cpu().reshape(28, 28)  # reshape vector to 2d array\n",
    "    plt.imshow(digit, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "generate_digit(0.0, 1.0), generate_digit(1.0, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_space(model, scale=1.0, n=25, digit_size=28, figsize=15):\n",
    "    # display a n*n 2D manifold of digits\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "\n",
    "    # construct a grid\n",
    "    grid_x = np.linspace(-scale, scale, n)\n",
    "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = torch.tensor([[xi, yi]], dtype=torch.float).to(device)\n",
    "            x_decoded = model.decode(z_sample)\n",
    "            digit = x_decoded[0].detach().cpu().reshape(digit_size, digit_size)\n",
    "            figure[\n",
    "                i * digit_size : (i + 1) * digit_size,\n",
    "                j * digit_size : (j + 1) * digit_size,\n",
    "            ] = digit\n",
    "\n",
    "    plt.figure(figsize=(figsize, figsize))\n",
    "    plt.title(\"VAE Latent Space Visualization\")\n",
    "    start_range = digit_size // 2\n",
    "    end_range = n * digit_size + start_range\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"mean, z [0]\")\n",
    "    plt.ylabel(\"var, z [1]\")\n",
    "    plt.imshow(figure, cmap=\"Greys_r\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_latent_space(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
